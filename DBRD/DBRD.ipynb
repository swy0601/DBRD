{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuClass":"premium","authorship_tag":"ABX9TyPikwRZk4l7aE0lo/TN5bLW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium","widgets":{"application/vnd.jupyter.widget-state+json":{"d97efc194a1e47a5aa08fb27289c3499":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8f9d61910ed34f5e8ba10c1bc4fdb6e1","IPY_MODEL_4e87b702dfbb44c0a07ff10911df60b5","IPY_MODEL_9d46ca486e144d3da56b1984be7cc0ea"],"layout":"IPY_MODEL_71bff33c5b14450596c5ea24138160d7"}},"8f9d61910ed34f5e8ba10c1bc4fdb6e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_575ee9edab844180a3bf300472af3f4a","placeholder":"​","style":"IPY_MODEL_7d933bca3b79471aa79b57827f9030c7","value":"Downloading (…)lve/main/config.json: 100%"}},"4e87b702dfbb44c0a07ff10911df60b5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c5e97d4b2a34e8f9e99b00be8943323","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d73a74427fc340a19779d192794305be","value":570}},"9d46ca486e144d3da56b1984be7cc0ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e638064bf68b47b984f586aaf8333082","placeholder":"​","style":"IPY_MODEL_20b41d56a3b849c08cb59732882cac45","value":" 570/570 [00:00&lt;00:00, 27.2kB/s]"}},"71bff33c5b14450596c5ea24138160d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"575ee9edab844180a3bf300472af3f4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d933bca3b79471aa79b57827f9030c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c5e97d4b2a34e8f9e99b00be8943323":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d73a74427fc340a19779d192794305be":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e638064bf68b47b984f586aaf8333082":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20b41d56a3b849c08cb59732882cac45":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9cd71c042a64479e9a587a2bb806ee76":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a084f999cbf8449aa5680c522d9aac8a","IPY_MODEL_0ddb4d2c28f341abb838b094669af9ca","IPY_MODEL_609d6bfaec0647708892eda8a0c8d047"],"layout":"IPY_MODEL_eeb35d5d849e4e7498be6af50fb7601f"}},"a084f999cbf8449aa5680c522d9aac8a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bbe99d3df9974fcd939075be4a8d7541","placeholder":"​","style":"IPY_MODEL_b297a98bab124365908a97234d42b793","value":"Downloading tf_model.h5: 100%"}},"0ddb4d2c28f341abb838b094669af9ca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd2afb1cc50748b4be538c26510f3543","max":536063208,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c32df93c5ce348d1bf53318f3985671e","value":536063208}},"609d6bfaec0647708892eda8a0c8d047":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_59fbf0e239044daaa4e67d7d1e836564","placeholder":"​","style":"IPY_MODEL_efd4dcedcfda4cad93afcd5c5d539830","value":" 536M/536M [00:03&lt;00:00, 141MB/s]"}},"eeb35d5d849e4e7498be6af50fb7601f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbe99d3df9974fcd939075be4a8d7541":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b297a98bab124365908a97234d42b793":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dd2afb1cc50748b4be538c26510f3543":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c32df93c5ce348d1bf53318f3985671e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"59fbf0e239044daaa4e67d7d1e836564":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efd4dcedcfda4cad93afcd5c5d539830":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"D0BE6unPc724","outputId":"412eaa25-b741-421f-a1d3-f068a9ca6dac","executionInfo":{"status":"ok","timestamp":1681972387683,"user_tz":-480,"elapsed":546001,"user":{"displayName":"Chenyang Xu","userId":"15376430863257277141"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m106.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.28.1\n","Mounted at /content/drive\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow==2.8\n","  Downloading tensorflow-2.8.0-cp39-cp39-manylinux2010_x86_64.whl (497.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.6/497.6 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8) (1.14.1)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8) (1.22.4)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8) (3.8.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8) (4.5.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8) (0.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8) (1.16.0)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8) (0.4.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8) (1.53.0)\n","Collecting tf-estimator-nightly==2.8.0.dev2021122109\n","  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 kB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8) (67.6.1)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8) (23.3.3)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8) (3.20.3)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8) (2.2.0)\n","Collecting keras-preprocessing>=1.1.1\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8) (1.6.3)\n","Collecting tensorboard<2.9,>=2.8\n","  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m105.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8) (16.0.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8) (0.32.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8) (1.4.0)\n","Collecting keras<2.9,>=2.8.0rc0\n","  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.8) (3.3.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow==2.8) (0.40.0)\n","Collecting google-auth-oauthlib<0.5,>=0.4.1\n","  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.8.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (2.27.1)\n","Collecting tensorboard-data-server<0.7.0,>=0.6.0\n","  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (2.17.3)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (3.4.3)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (2.2.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.9)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (5.3.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8) (6.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2022.12.7)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8) (2.1.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.15.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.2.2)\n","Installing collected packages: tf-estimator-nightly, keras, tensorboard-data-server, keras-preprocessing, google-auth-oauthlib, tensorboard, tensorflow\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.12.0\n","    Uninstalling keras-2.12.0:\n","      Successfully uninstalled keras-2.12.0\n","  Attempting uninstall: tensorboard-data-server\n","    Found existing installation: tensorboard-data-server 0.7.0\n","    Uninstalling tensorboard-data-server-0.7.0:\n","      Successfully uninstalled tensorboard-data-server-0.7.0\n","  Attempting uninstall: google-auth-oauthlib\n","    Found existing installation: google-auth-oauthlib 1.0.0\n","    Uninstalling google-auth-oauthlib-1.0.0:\n","      Successfully uninstalled google-auth-oauthlib-1.0.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.12.2\n","    Uninstalling tensorboard-2.12.2:\n","      Successfully uninstalled tensorboard-2.12.2\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.12.0\n","    Uninstalling tensorflow-2.12.0:\n","      Successfully uninstalled tensorflow-2.12.0\n","Successfully installed google-auth-oauthlib-0.4.6 keras-2.8.0 keras-preprocessing-1.1.2 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorflow-2.8.0 tf-estimator-nightly-2.8.0.dev2021122109\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["keras","tensorboard","tensorflow"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following packages will be REMOVED:\n","  libcudnn8-dev\n","The following held packages will be changed:\n","  libcudnn8\n","The following packages will be DOWNGRADED:\n","  libcudnn8\n","0 upgraded, 0 newly installed, 1 downgraded, 1 to remove and 22 not upgraded.\n","Need to get 430 MB of archives.\n","After this operation, 1,153 MB disk space will be freed.\n","Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  libcudnn8 8.1.0.77-1+cuda11.2 [430 MB]\n","Fetched 430 MB in 5s (87.9 MB/s)\n","(Reading database ... 122352 files and directories currently installed.)\n","Removing libcudnn8-dev (8.7.0.84-1+cuda11.8) ...\n","update-alternatives: removing manually selected alternative - switching libcudnn to auto mode\n","\u001b[1mdpkg:\u001b[0m \u001b[1;33mwarning:\u001b[0m downgrading libcudnn8 from 8.7.0.84-1+cuda11.8 to 8.1.0.77-1+cuda11.2\n","(Reading database ... 122319 files and directories currently installed.)\n","Preparing to unpack .../libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb ...\n","Unpacking libcudnn8 (8.1.0.77-1+cuda11.2) over (8.7.0.84-1+cuda11.8) ...\n","Setting up libcudnn8 (8.1.0.77-1+cuda11.2) ...\n"]}],"source":["!pip install transformers\n","import pandas as pd\n","import numpy as np\n","import torch\n","import tensorflow as tf\n","from google.colab import drive\n","drive.mount('/content/drive')\n","from transformers import TFAutoModel\n","from tqdm import tqdm\n","from keras.utils import np_utils\n","!pip install tensorflow==2.8\n","!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"]},{"cell_type":"markdown","metadata":{"id":"mtwfJyIVZxWf"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":675,"referenced_widgets":["d97efc194a1e47a5aa08fb27289c3499","8f9d61910ed34f5e8ba10c1bc4fdb6e1","4e87b702dfbb44c0a07ff10911df60b5","9d46ca486e144d3da56b1984be7cc0ea","71bff33c5b14450596c5ea24138160d7","575ee9edab844180a3bf300472af3f4a","7d933bca3b79471aa79b57827f9030c7","7c5e97d4b2a34e8f9e99b00be8943323","d73a74427fc340a19779d192794305be","e638064bf68b47b984f586aaf8333082","20b41d56a3b849c08cb59732882cac45","9cd71c042a64479e9a587a2bb806ee76","a084f999cbf8449aa5680c522d9aac8a","0ddb4d2c28f341abb838b094669af9ca","609d6bfaec0647708892eda8a0c8d047","eeb35d5d849e4e7498be6af50fb7601f","bbe99d3df9974fcd939075be4a8d7541","b297a98bab124365908a97234d42b793","dd2afb1cc50748b4be538c26510f3543","c32df93c5ce348d1bf53318f3985671e","59fbf0e239044daaa4e67d7d1e836564","efd4dcedcfda4cad93afcd5c5d539830"]},"executionInfo":{"elapsed":27783,"status":"ok","timestamp":1681972708808,"user":{"displayName":"Chenyang Xu","userId":"15376430863257277141"},"user_tz":-480},"id":"-pNneOy4lOC0","outputId":"26145d61-fb2d-451f-8d3b-871e2deec8d6"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d97efc194a1e47a5aa08fb27289c3499"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading tf_model.h5:   0%|          | 0.00/536M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cd71c042a64479e9a587a2bb806ee76"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","WARNING:tensorflow:From <ipython-input-2-540715fbb925>:9: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.config.list_physical_devices('GPU')` instead.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_2 (InputLayer)           [(None, 50)]         0           []                               \n","                                                                                                  \n"," input_3 (InputLayer)           [(None, 50)]         0           []                               \n","                                                                                                  \n"," model (Functional)             (None, 100)          110618840   ['input_2[0][0]',                \n","                                                                  'input_3[0][0]']                \n","                                                                                                  \n"," concatenate_2 (Concatenate)    (None, 200)          0           ['model[0][0]',                  \n","                                                                  'model[1][0]']                  \n","                                                                                                  \n"," dense_2 (Dense)                (None, 2)            402         ['concatenate_2[0][0]']          \n","                                                                                                  \n","==================================================================================================\n","Total params: 110,619,242\n","Trainable params: 1,135,002\n","Non-trainable params: 109,484,240\n","__________________________________________________________________________________________________\n"]}],"source":["from keras import backend as K\n","from keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout,Reshape,Softmax,LSTM, Dropout, Bidirectional\n","from keras.models import Model\n","import numpy as np\n","BERT = TFAutoModel.from_pretrained('bert-base-uncased')\n","for layer in BERT.layers:\n","    layer.trainable = False #使BERT层的参数不参与反相传播\n","def embedding(inputs_id):\n","    if tf.test.is_gpu_available():\n","        device = \"/gpu:0\"\n","    else:\n","        device = \"/cpu:0\"\n","    with tf.device(device):\n","      outputs = BERT(inputs_id, output_hidden_states=True, training=False)\n","      hidden = outputs[2]\n","      embeddings = tf.stack(hidden, axis=0)\n","      final = tf.reduce_sum(embeddings[-4:], axis=0)\n","    del hidden,embeddings,outputs\n","    return final\n","def Siamese():\n","    input_shape = (50,)\n","    input_dtype = tf.int32\n","    input = tf.keras.layers.Input(shape=input_shape, dtype=input_dtype)\n","    X_1 = embedding(input)\n","    X_1_1 = Conv1D(200, kernel_size=1, strides=1, activation='relu')(X_1)\n","    X_1_1 = tf.keras.layers.BatchNormalization()(X_1_1)\n","    X_1_1 = MaxPooling1D(pool_size=300,padding='same')(X_1_1)\n","    X_1_1 = Flatten()(X_1_1)\n","\n","    X_1_2 = Conv1D(200, kernel_size=2, strides=1, activation='relu')(X_1)\n","    X_1_2 = tf.keras.layers.BatchNormalization()(X_1_2)\n","    X_1_2 = MaxPooling1D(pool_size=299,padding='same')(X_1_2)\n","    X_1_2 = Flatten()(X_1_2)\n","\n","    X_1_3 = Conv1D(200, kernel_size=3, strides=1, activation='relu')(X_1)\n","    X_1_3 = tf.keras.layers.BatchNormalization()(X_1_3)\n","    X_1_3 = MaxPooling1D(pool_size=298,padding='same')(X_1_3)\n","    X_1_3 = Flatten()(X_1_3)\n","\n","    X_1 = tf.keras.layers.Concatenate(axis=-1)([X_1_1, X_1_2])\n","    output = tf.keras.layers.Concatenate(axis=-1)([X_1, X_1_3])\n","    # output = lstm_layer(X_1)\n","    output = Dropout(0.6)(output)\n","    output = Dense(300, activation='relu')(output)\n","    output = tf.keras.layers.BatchNormalization(axis=-1)(output)\n","\n","    output = Dropout(0.4)(output)\n","    output = Dense(100, activation='relu')(output)\n","    output = tf.keras.layers.BatchNormalization(axis=-1)(output)\n","\n","\n","    sub_model = Model(input, output)\n","\n","    # Then define the tell-digits-apart model\n","    left = Input(shape=input_shape)\n","    right = Input(shape=input_shape)\n","\n","    # The vision model will be shared, weights and all\n","    left_output = sub_model(left)\n","    right_output = sub_model(right)\n","\n","    out =  tf.keras.layers.Concatenate(axis=-1)([left_output,right_output])\n","    prediction = tf.keras.layers.Dense(2, activation='softmax')(out)\n","\n","    siamese_model = Model([left, right], prediction)\n","    return siamese_model\n","\n","DBRD = Siamese()\n","DBRD.summary()\n","\n","\n","\n","\n"]},{"cell_type":"code","source":[],"metadata":{"id":"noa14S6nC1Ln"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K0dzZ3xr5pPp"},"outputs":[],"source":["import pickle\n","left = tf.convert_to_tensor(torch.load('/content/drive/MyDrive/data/token50/eclipse_token1.pt'))\n","right = tf.convert_to_tensor(torch.load('/content/drive/MyDrive/data/token50/eclipse_token2.pt'))\n","\n","with open('/content/drive/MyDrive/data/label/ec_l.pkl', 'rb') as f:\n","    label = pickle.load(f)\n","label = [0 if i == -1 else i for i in label]\n","label = tf.convert_to_tensor(label, dtype=tf.int32)\n","label = np_utils.to_categorical(label, 2)\n","with open('/content/drive/MyDrive/data/eclipse_normal/eclipse_ct.pkl', 'rb') as f:\n","    p1 = pickle.load(f)\n","    p1 = tf.convert_to_tensor(p1)\n","with open('/content/drive/MyDrive/data/eclipse_normal/eclipse_pr.pkl', 'rb') as f:\n","    p2 = pickle.load(f)\n","    p2 = tf.convert_to_tensor(p2)\n","with open('/content/drive/MyDrive/data/eclipse_normal/eclipse_sv.pkl', 'rb') as f:\n","    p3 = pickle.load(f)\n","    p3 = tf.convert_to_tensor(p3)\n","\n","RANDOM_SEED =22\n","left = tf.random.shuffle(left, seed=RANDOM_SEED )\n","right = tf.random.shuffle(right, seed=RANDOM_SEED )\n","labels = tf.random.shuffle(label, seed=RANDOM_SEED )\n","p1 = tf.random.shuffle(p1, seed=RANDOM_SEED )\n","p2 = tf.random.shuffle(p2, seed=RANDOM_SEED )\n","p3 = tf.random.shuffle(p3, seed=RANDOM_SEED )\n"]},{"cell_type":"code","source":["data_size = len(labels)\n","train_size = int(0.8 * data_size)\n","val_size = int(0.1 * data_size)\n","test_size = data_size - train_size - val_size\n","\n","split_left = tf.split(left, [train_size, val_size, test_size], axis=0)\n","split_right = tf.split(right, [train_size, val_size, test_size], axis=0)\n","split_p1 = tf.split(p1, [train_size, val_size, test_size], axis=0)\n","split_p2 = tf.split(p2, [train_size, val_size, test_size], axis=0)\n","split_p3 = tf.split(p3, [train_size, val_size, test_size], axis=0)\n","split_labels = tf.split(labels, [train_size, val_size, test_size], axis=0)\n","\n","train_left = split_left[0]\n","train_right = split_right[0]\n","train_label = split_labels[0]\n","train_p1 = split_p1[0]\n","train_p2 = split_p2[0]\n","train_p3 = split_p3[0]\n","\n","val_left = split_left[1]\n","val_right = split_right[1]\n","val_label = split_labels[1]\n","val_p1 = split_p1[1]\n","val_p2 = split_p2[1]\n","val_p3 = split_p3[1]\n","\n","\n","test_left = split_left[2]\n","test_right = split_right[2]\n","test_label = split_labels[2]\n","test_p1 = split_p1[2]\n","test_p2 = split_p2[2]\n","test_p3 = split_p3[2]"],"metadata":{"id":"TLZ8uM8haodC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train_left = train_left[:500]\n","# train_right = train_right[:500]\n","# train_label = train_label[:500]\n","# train_p1 = train_p1[:500]\n","# train_p2 = train_p2[:500]\n","# train_p3 = train_p3[:500]\n","\n","# val_left = val_left[:500]\n","# val_right = val_right[:500]\n","# val_label = val_label[:500]\n","# val_p1 = val_p1[:500]\n","# val_p2 = val_p2[:500]\n","# val_p3 = val_p3[:500]"],"metadata":{"id":"mJkisv1qAfEF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"33-sTQLqFwbI"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2055634,"status":"ok","timestamp":1681975838547,"user":{"displayName":"Chenyang Xu","userId":"15376430863257277141"},"user_tz":-480},"id":"fsmS-uYHjTE1","outputId":"e4dc6809-717a-40f6-c0b6-60d2c6147f32"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/100\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/3091 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/keras/backend.py:5703: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n","  \n","WARNING:tensorflow:AutoGraph could not transform <bound method _BaseOptimizer._update_step_xla of <tensorflow.python.eager.polymorphic_function.tracing_compiler.TfMethodTarget object at 0x7efcb1a8fb50>> and will run it as-is.\n","Cause: Unable to locate the source code of <bound method _BaseOptimizer._update_step_xla of <tensorflow.python.eager.polymorphic_function.tracing_compiler.TfMethodTarget object at 0x7efcb1a8fb50>>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["WARNING: AutoGraph could not transform <bound method _BaseOptimizer._update_step_xla of <tensorflow.python.eager.polymorphic_function.tracing_compiler.TfMethodTarget object at 0x7efcb1a8fb50>> and will run it as-is.\n","Cause: Unable to locate the source code of <bound method _BaseOptimizer._update_step_xla of <tensorflow.python.eager.polymorphic_function.tracing_compiler.TfMethodTarget object at 0x7efcb1a8fb50>>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 3091/3091 [02:56<00:00, 17.52it/s]\n","100%|██████████| 387/387 [02:44<00:00,  2.35it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["TP: 14990.0\n","TN: 3304.0\n","FP: 5521.0\n","FN: 911.0\n","Training accuracy: 0.72559667\n","Training loss: 1.0106362\n","Validation accuracy: 0.73986894\n","Validation loss: 0.98248357\n","Best acc: tf.Tensor(0.73986894, shape=(), dtype=float32)\n","Best loss: tf.Tensor(0.98248357, shape=(), dtype=float32)\n","Wait: 0\n","Epoch 2/100\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 3091/3091 [02:24<00:00, 21.37it/s]\n","100%|██████████| 387/387 [02:43<00:00,  2.36it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["TP: 14957.0\n","TN: 3858.0\n","FP: 4967.0\n","FN: 944.0\n","Training accuracy: 0.76459855\n","Training loss: 0.9412512\n","Validation accuracy: 0.7609399\n","Validation loss: 0.95055956\n","Best acc: tf.Tensor(0.7609399, shape=(), dtype=float32)\n","Best loss: tf.Tensor(0.95055956, shape=(), dtype=float32)\n","Wait: 0\n","Epoch 3/100\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 3091/3091 [02:24<00:00, 21.37it/s]\n","100%|██████████| 387/387 [02:44<00:00,  2.36it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["TP: 14275.0\n","TN: 4842.0\n","FP: 3983.0\n","FN: 1626.0\n","Training accuracy: 0.79796875\n","Training loss: 0.891086\n","Validation accuracy: 0.7731538\n","Validation loss: 0.94807917\n","Best acc: tf.Tensor(0.7731538, shape=(), dtype=float32)\n","Best loss: tf.Tensor(0.94807917, shape=(), dtype=float32)\n","Wait: 0\n","Epoch 4/100\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3091/3091 [02:24<00:00, 21.37it/s]\n","100%|██████████| 387/387 [02:43<00:00,  2.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TP: 14143.0\n","TN: 5159.0\n","FP: 3666.0\n","FN: 1758.0\n","Training accuracy: 0.82388747\n","Training loss: 0.84621614\n","Validation accuracy: 0.7806358\n","Validation loss: 0.95841426\n","Best acc: tf.Tensor(0.7806358, shape=(), dtype=float32)\n","Best loss: tf.Tensor(0.94807917, shape=(), dtype=float32)\n","Wait: 0\n","Epoch 5/100\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3091/3091 [02:24<00:00, 21.37it/s]\n","100%|██████████| 387/387 [02:43<00:00,  2.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TP: 14792.0\n","TN: 4579.0\n","FP: 4246.0\n","FN: 1109.0\n","Training accuracy: 0.84332013\n","Training loss: 0.8108644\n","Validation accuracy: 0.78342634\n","Validation loss: 0.9576651\n","Best acc: tf.Tensor(0.78342634, shape=(), dtype=float32)\n","Best loss: tf.Tensor(0.94807917, shape=(), dtype=float32)\n","Wait: 0\n","Epoch 6/100\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3091/3091 [02:24<00:00, 21.36it/s]\n","100%|██████████| 387/387 [02:43<00:00,  2.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TP: 13561.0\n","TN: 5488.0\n","FP: 3337.0\n","FN: 2340.0\n","Training accuracy: 0.85551864\n","Training loss: 0.7847538\n","Validation accuracy: 0.7704036\n","Validation loss: 0.9678447\n","Best acc: tf.Tensor(0.78342634, shape=(), dtype=float32)\n","Best loss: tf.Tensor(0.94807917, shape=(), dtype=float32)\n","Wait: 1\n","Epoch 7/100\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3091/3091 [02:24<00:00, 21.36it/s]\n","100%|██████████| 387/387 [02:43<00:00,  2.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TP: 13096.0\n","TN: 5803.0\n","FP: 3022.0\n","FN: 2805.0\n","Training accuracy: 0.8715744\n","Training loss: 0.75194126\n","Validation accuracy: 0.7643371\n","Validation loss: 1.0770543\n","Best acc: tf.Tensor(0.78342634, shape=(), dtype=float32)\n","Best loss: tf.Tensor(0.94807917, shape=(), dtype=float32)\n","Wait: 2\n","Epoch 8/100\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3091/3091 [02:24<00:00, 21.38it/s]\n","100%|██████████| 387/387 [02:43<00:00,  2.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TP: 12627.0\n","TN: 6100.0\n","FP: 2725.0\n","FN: 3274.0\n","Training accuracy: 0.88450086\n","Training loss: 0.7231615\n","Validation accuracy: 0.7573809\n","Validation loss: 1.1388571\n","Best acc: tf.Tensor(0.78342634, shape=(), dtype=float32)\n","Best loss: tf.Tensor(0.94807917, shape=(), dtype=float32)\n","Wait: 3\n","Epoch 9/100\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3091/3091 [02:24<00:00, 21.36it/s]\n","100%|██████████| 387/387 [02:43<00:00,  2.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TP: 11899.0\n","TN: 6390.0\n","FP: 2435.0\n","FN: 4002.0\n","Training accuracy: 0.8973161\n","Training loss: 0.6958683\n","Validation accuracy: 0.73966676\n","Validation loss: 1.2607397\n","Best acc: tf.Tensor(0.78342634, shape=(), dtype=float32)\n","Best loss: tf.Tensor(0.94807917, shape=(), dtype=float32)\n","Wait: 4\n","Epoch 10/100\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3091/3091 [02:24<00:00, 21.35it/s]\n","100%|██████████| 387/387 [02:42<00:00,  2.38it/s]\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["TP: 13306.0\n","TN: 5657.0\n","FP: 3168.0\n","FN: 2595.0\n","Training accuracy: 0.9063601\n","Training loss: 0.6728688\n","Validation accuracy: 0.7669255\n","Validation loss: 1.1876303\n"]}],"source":["\n","TP = tf.keras.metrics.TruePositives()\n","TN = tf.keras.metrics.TrueNegatives()\n","FP = tf.keras.metrics.FalsePositives()\n","FN = tf.keras.metrics.FalseNegatives()\n","def evaluate(left, right, labels, model, loss_fn, p1, p2, p3, batch_size):\n","\n","    for i in tqdm(range(0, len(left), batch_size)):\n","        val_left_batch = left[i:i+batch_size]\n","        val_right_batch = right[i:i+batch_size]\n","        val_labels_batch = labels[i:i+batch_size]\n","        val_p1_batch = p1[i:i+batch_size]\n","        val_p2_batch = p2[i:i+batch_size]\n","        val_p3_batch = p3[i:i+batch_size]\n","        val_pred = model([val_left_batch, val_right_batch])\n","        val_loss = loss_fn(val_labels_batch,val_pred)+ tf.dtypes.cast(tf.math.reduce_mean(val_p1_batch),tf.float32)+ tf.dtypes.cast(tf.math.reduce_mean(val_p2_batch),tf.float32) + tf.dtypes.cast(tf.math.reduce_mean(val_p3_batch),tf.float32)\n","        val_accuracy_metric.update_state(val_labels_batch, val_pred)\n","\n","        TP.update_state(val_labels_batch[:, 0], val_pred[:, 0])\n","        TN.update_state(val_labels_batch[:, 0], val_pred[:, 0])\n","        FP.update_state(val_labels_batch[:, 0], val_pred[:, 0])\n","        FN.update_state(val_labels_batch[:, 0], val_pred[:, 0])\n","        val_loss_tracker.update_state(val_loss)\n","    print(\"TP:\",TP.result().numpy())\n","    print(\"TN:\",TN.result().numpy())\n","    print(\"FP:\",FP.result().numpy())\n","    print(\"FN:\",FN.result().numpy())\n","    TP.reset_states()\n","    TN.reset_states()\n","    FP.reset_states()\n","    FN.reset_states()\n","\n","#额外训练参数\n","# w1 = tf.Variable(tf.random.normal([1], mean=0.0, stddev=1.0))\n","# w2 = tf.Variable(tf.random.normal([1], mean=0.0, stddev=1.0))\n","# w3 = tf.Variable(tf.random.normal([1], mean=0.0, stddev=1.0))\n","loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n","val_loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n","accuracy_metric = tf.keras.metrics.BinaryAccuracy()\n","val_accuracy_metric = tf.keras.metrics.BinaryAccuracy()\n","\n","@tf.function\n","def train_step(inputs, labels, model, optimizer, loss_fn, p1,p2,p3):#再加入一个验证集\n","  if tf.test.is_gpu_available():\n","    device = \"/gpu:0\"\n","  else:\n","    device = \"/cpu:0\"\n","  with tf.device(device):\n","    with tf.GradientTape() as tape:\n","        left, right = inputs\n","        pred = model([left, right])\n","        loss = loss_fn(labels, pred) + tf.dtypes.cast(tf.math.reduce_mean(p1),tf.float32)+ tf.dtypes.cast(tf.math.reduce_mean(p2),tf.float32) + tf.dtypes.cast(tf.math.reduce_mean(p3),tf.float32)\n","    # Compute gradients and update weights\n","    grads = tape.gradient(loss, model.trainable_weights)\n","    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n","    # Update metrics\n","    accuracy_metric.update_state(labels, pred)\n","    loss_tracker.update_state(loss)\n","\n","\n","\n","# Define optimizer and loss function\n","optimizer = tf.keras.optimizers.Adam()\n","loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","\n","\n","\n","\n","# Train the model\n","epochs = 100\n","batch_size = 64\n","patience = 5\n","wait = 0\n","best = 0\n","best_loss = 100\n","\n","# Define optimizer and loss function\n","optimizer = tf.keras.optimizers.Adam()\n","loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","\n","\n","\n","# Train the model\n","for epoch in range(epochs):\n","    print(\"Epoch {}/{}\".format(epoch+1, epochs))\n","    for i in tqdm(range(0, len(train_left), batch_size)):\n","        left_batch = train_left[i:i+batch_size]\n","        right_batch = train_right[i:i+batch_size]\n","        labels_batch = train_label[i:i+batch_size]\n","        p1_batch = train_p1[i:i+batch_size]\n","        p2_batch = train_p2[i:i+batch_size]\n","        p3_batch = train_p3[i:i+batch_size]\n","\n","        # Train on batch\n","        train_step([left_batch, right_batch], labels_batch, DBRD, optimizer, loss_fn, p1_batch, p2_batch, p3_batch)\n","\n","    # Evaluate on validation set\n","    evaluate(val_left, val_right, val_label, DBRD, loss_fn, val_p1, val_p2, val_p3, batch_size)\n","\n","    # Print training progress\n","    print(\"Training accuracy:\", accuracy_metric.result().numpy())\n","    print(\"Training loss:\", loss_tracker.result().numpy())\n","    print(\"Validation accuracy:\", val_accuracy_metric.result().numpy())\n","    print(\"Validation loss:\", val_loss_tracker.result().numpy())\n","    val_loss = val_loss_tracker.result()\n","    val_acc = val_accuracy_metric.result()\n","    # Reset metrics at the end of each epoch\n","    accuracy_metric.reset_states()\n","    loss_tracker.reset_states()\n","    val_loss_tracker.reset_states()\n","    val_accuracy_metric.reset_states()\n","\n","    wait += 1\n","\n","    if val_acc > best:\n","      best = val_acc\n","      wait = 0\n","    if val_loss < best_loss:\n","      best_loss = val_loss\n","      wait = 0\n","\n","    if wait >= patience:\n","      break\n","    print(\"Best acc:\",best)\n","    print(\"Best loss:\",best_loss)\n","    print(\"Wait:\",wait)\n","# Save the model\n","DBRD.save(\"model.h5\")"]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"utrx6bWALOwF","executionInfo":{"status":"ok","timestamp":1682046797777,"user_tz":-480,"elapsed":413,"user":{"displayName":"Chenyang Xu","userId":"15376430863257277141"}},"outputId":"6a89a438-005e-4da1-8800-11f8063ce31f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Apr 21 03:13:17 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["\n","DBRD.save(\"/content/drive/MyDrive/model_50_ec.h5\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"61ch2tjqDAez","executionInfo":{"status":"ok","timestamp":1681977050516,"user_tz":-480,"elapsed":1542,"user":{"displayName":"Chenyang Xu","userId":"15376430863257277141"}},"outputId":"e8ab211b-8b66-48b6-b23d-384453048bcf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"eZMuZsWa4NWG"}}]}