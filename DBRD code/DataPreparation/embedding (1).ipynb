{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMzkWdfpT9ilOUNQjGt8dqz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["!pip install transformers\n","import pandas as pd\n","import numpy as np\n","import torch\n","import tensorflow as tf\n","from google.colab import drive \n","drive.mount('/content/drive')\n","from transformers import AutoTokenizer,AutoModel\n","from torch.utils.data import TensorDataset\n","from tqdm import tqdm\n","tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\", use_fast=True)\n","model = AutoModel.from_pretrained('bert-base-uncased').eval()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N4acxcCAN6jO","executionInfo":{"status":"ok","timestamp":1678690733995,"user_tz":-480,"elapsed":25688,"user":{"displayName":"Chenyang Xu","userId":"18263616641238114117"}},"outputId":"50dd262b-becf-4ec3-d5db-e3b41a66b756"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.26.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.25.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.14)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (4.0.0)\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["# import re\n","\n","# def remove_special_chars(text):\n","\n","#   clean_text = re.sub(r\"[^\\w\\s.,]\", \"\", text)\n","#   return re.sub(r\"\\b\\w\\b\", \"\", clean_text)\n","# from tqdm import tqdm\n","\n","# def limit_string_length(string_list, max_word_count=500):\n","#     \"\"\"限制字符串列表中每个字符串的长度\"\"\"\n","#     for i, string in tqdm(enumerate(string_list), total=len(string_list)):\n","#         string = remove_special_chars(string)\n","#         words = string.split()[:max_word_count]\n","#         string_list[i] = \" \".join(words)\n","#     return string_list\n"],"metadata":{"id":"KepskyoiDLBK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["a = torch.load('/content/drive/MyDrive/data/token/open_token1.pt')"],"metadata":{"id":"Fq5P-0-1YDhC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tqdm import tqdm\n","import math\n","\n","def embedding(input_ids, batch_size=100):\n","    input_ids.cpu()\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","\n","    with torch.no_grad():\n","        num_parts = 50#将input_ids 平均分成50份(可调整),每处理完一份保存到硬盘文件夹然后清空RAM\n","        part_size = math.ceil(len(input_ids) / num_parts)#例如总共95806条文本,每份95806/50= 1916条文本，一份有1916/100个batch\n","        num_batches = math.ceil(part_size / batch_size)\n","\n","        for i in range(num_parts):\n","            start = i * part_size\n","            end = min((i + 1) * part_size, len(input_ids))\n","            part_embeddings = []\n","\n","            # 每份的batch szie\n","            for j in tqdm(range(num_batches)):\n","                batch_start = start + j * batch_size\n","                batch_end = min(start + (j + 1) * batch_size, end)\n","\n","                input_ids_batch = input_ids[batch_start:batch_end].to(device)\n","\n","                outputs = model(input_ids_batch, output_hidden_states=True)\n","                hidden_states = outputs[2]\n","\n","                token_embeddings_batch = torch.stack(hidden_states, dim=0)\n","                tem = torch.sum(token_embeddings_batch[-4:], dim=0).cpu()\n","                part_embeddings.append(tem)\n","                del token_embeddings_batch, hidden_states,outputs,input_ids_batch\n","                torch.cuda.empty_cache()\n","\n","            part_embeddings = torch.cat(part_embeddings, dim=0)\n","            #路径根据处理的数据集改一下，放到一个文件夹里\n","            torch.save(part_embeddings, f'openoffice_b2_part_{i}.pt')\n","\n","            del part_embeddings\n","            torch.cuda.empty_cache()\n","#最终会在文件夹中保存50个.pt的张量文件，之后按顺序批量读取合并成一个就好了，一定要按顺序要不和标签啥的不匹配了\n","#每个数据集有两个token文件，例如eclipse_token1.pt和eclipse_token1.pt。这两个文件都需要处理，分文件夹保存之后读取\n","#eclipse_token1生成的50个张量文件合成一个新张量，eclipse_token2生成的50个张量文件合成另一个新张量。按照此类方法处理三个数据集\n","#上述的part_size = 50 仅为示例，可自行调整。\n","    return 0\n"],"metadata":{"id":"F7cuqKzYryA5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"EzKStY9_huDT"}},{"cell_type":"code","source":[" c = embedding(a[:111])#用111条文本测试了一下，能够正常运行"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1WzhBtbVhPjJ","executionInfo":{"status":"ok","timestamp":1678690748747,"user_tz":-480,"elapsed":12028,"user":{"displayName":"Chenyang Xu","userId":"18263616641238114117"}},"outputId":"a04bc001-59a7-4a05-ff1e-0267ac73edeb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n","100%|██████████| 1/1 [00:00<00:00,  8.86it/s]\n","100%|██████████| 1/1 [00:00<00:00, 10.02it/s]\n","100%|██████████| 1/1 [00:00<00:00, 10.07it/s]\n","100%|██████████| 1/1 [00:00<00:00, 10.13it/s]\n","100%|██████████| 1/1 [00:00<00:00,  9.78it/s]\n","100%|██████████| 1/1 [00:00<00:00, 10.02it/s]\n","100%|██████████| 1/1 [00:00<00:00,  9.70it/s]\n","100%|██████████| 1/1 [00:00<00:00,  9.57it/s]\n","100%|██████████| 1/1 [00:00<00:00,  9.82it/s]\n","100%|██████████| 1/1 [00:00<00:00,  9.80it/s]\n","100%|██████████| 1/1 [00:00<00:00,  9.73it/s]\n","100%|██████████| 1/1 [00:00<00:00, 10.05it/s]\n","100%|██████████| 1/1 [00:00<00:00,  9.71it/s]\n","100%|██████████| 1/1 [00:00<00:00, 10.01it/s]\n","100%|██████████| 1/1 [00:00<00:00,  9.84it/s]\n","100%|██████████| 1/1 [00:00<00:00,  9.92it/s]\n","100%|██████████| 1/1 [00:00<00:00,  9.58it/s]\n","100%|██████████| 1/1 [00:00<00:00,  9.67it/s]\n","100%|██████████| 1/1 [00:00<00:00,  9.69it/s]\n","100%|██████████| 1/1 [00:00<00:00, 10.03it/s]\n","100%|██████████| 1/1 [00:00<00:00,  9.60it/s]\n","100%|██████████| 1/1 [00:00<00:00,  9.21it/s]\n","100%|██████████| 1/1 [00:00<00:00,  8.98it/s]\n","100%|██████████| 1/1 [00:00<00:00,  9.11it/s]\n","100%|██████████| 1/1 [00:00<00:00, 10.13it/s]\n","100%|██████████| 1/1 [00:00<00:00,  8.56it/s]\n","100%|██████████| 1/1 [00:00<00:00,  9.60it/s]\n","100%|██████████| 1/1 [00:00<00:00,  7.11it/s]\n","100%|██████████| 1/1 [00:00<00:00,  8.29it/s]\n","100%|██████████| 1/1 [00:00<00:00,  8.76it/s]\n","100%|██████████| 1/1 [00:00<00:00,  7.82it/s]\n","100%|██████████| 1/1 [00:00<00:00,  9.47it/s]\n","100%|██████████| 1/1 [00:00<00:00,  7.36it/s]\n","100%|██████████| 1/1 [00:00<00:00,  8.92it/s]\n","100%|██████████| 1/1 [00:00<00:00,  7.56it/s]\n","100%|██████████| 1/1 [00:00<00:00,  9.03it/s]\n","100%|██████████| 1/1 [00:00<00:00, 52.88it/s]\n","100%|██████████| 1/1 [00:00<00:00, 67.42it/s]\n","100%|██████████| 1/1 [00:00<00:00, 38.65it/s]\n","100%|██████████| 1/1 [00:00<00:00, 58.64it/s]\n","100%|██████████| 1/1 [00:00<00:00, 47.25it/s]\n","100%|██████████| 1/1 [00:00<00:00, 63.04it/s]\n","100%|██████████| 1/1 [00:00<00:00, 52.41it/s]\n","100%|██████████| 1/1 [00:00<00:00, 63.86it/s]\n","100%|██████████| 1/1 [00:00<00:00, 69.56it/s]\n","100%|██████████| 1/1 [00:00<00:00, 58.16it/s]\n","100%|██████████| 1/1 [00:00<00:00, 57.72it/s]\n","100%|██████████| 1/1 [00:00<00:00, 54.54it/s]\n","100%|██████████| 1/1 [00:00<00:00, 60.88it/s]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"qkNvqby4xejQ"},"execution_count":null,"outputs":[]}]}